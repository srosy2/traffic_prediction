{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Includes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "from math import ceil, floor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"..\"\n",
    "data_dir = os.path.join(root_path, \"unpacked\")\n",
    "\n",
    "data_files = os.listdir(data_dir)  # target files\n",
    "data_files = [x for x in data_files if x != 'readme.txt']  # remove readme\n",
    "\n",
    "\n",
    "def file_to_df(file):\n",
    "    \"\"\"Open file and create pandas data frame\"\"\"\n",
    "    full_path = os.path.join(data_dir, file)\n",
    "    return pd.read_csv(full_path, sep=';', decimal=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3', '1', '5', '28', '19'}\n"
     ]
    }
   ],
   "source": [
    "regex_pattern = r\"vehicle(\\d*)\"  # ID is integer number comes right after vehicle word\n",
    "compiled_pattern = re.compile(regex_pattern)\n",
    "ids = compiled_pattern.findall(''.join(data_files))  # apply pattern to all file names\n",
    "ids = set(ids)  # get a set of unique numbers\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load info about a single vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file_id(v_id, key_lexem):\n",
    "    \"\"\"Key lexem determines file, for example, 'fuelLevel'\"\"\"\n",
    "    regex_pattern = re.compile(f\"(vehicle{v_id}_{key_lexem}\" + r\"_(\\w|\\d|_)*\\.csv)\")  # pattern to find appropriate name\n",
    "    pattern_match = regex_pattern.search('|'.join(data_files))  # search on a whole file set\n",
    "    needed_file = pattern_match.group(1)  # the file is found, now we can open it\n",
    "    return file_to_df(needed_file)\n",
    "    \n",
    "possible_lexems = ['fuelLevel', 'ingection', 'refueling2', 'speedAndHeight', 'tachometer']\n",
    "\n",
    "def load_all_files_id(v_id):\n",
    "    \"\"\"Generates a dictionary of all files describing a single vehicle\"\"\"\n",
    "    return {lex: open_file_id(v_id, lex) for lex in possible_lexems}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_base = {v_id: load_all_files_id(v_id) for v_id in ids}  # load all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate main statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def velocity_data(v_id, df_holder=raw_data_base):  # velocity statistics\n",
    "    v_df = df_holder[v_id]['speedAndHeight']\n",
    "    mean_v = np.mean(v_df[v_df['SPEED'] > 0]['SPEED'])\n",
    "    med_v = np.median(v_df[v_df['SPEED'] > 0]['SPEED'])\n",
    "    max_v = np.max(v_df['SPEED'])\n",
    "    max_trimmed_v = np.percentile(v_df[v_df['SPEED'] > 0]['SPEED'], q=99)\n",
    "    return {'mean_v': mean_v, 'med_v': med_v, 'max_v': max_v, 'max_trim_v': max_trimmed_v}\n",
    "\n",
    "def tachometer_data(v_id, df_holder=raw_data_base):  # tachometer statistics\n",
    "    t_df = df_holder[v_id]['tachometer']\n",
    "    mean_t = np.mean(t_df[t_df['BEVALUE'] > 0]['BEVALUE'])\n",
    "    max_t = np.max(t_df['BEVALUE'])\n",
    "    quantiles = np.percentile(t_df[t_df['BEVALUE'] > 0]['BEVALUE'], q=[25, 50, 75, 80, 99])\n",
    "    return {'mean_t': mean_t, 'max_t': max_t, 'quant_t': quantiles}\n",
    "\n",
    "def fuel_lvl_data(v_id, df_holder=raw_data_base):  # fuel level statistics\n",
    "    f_df = df_holder[v_id]['fuelLevel']\n",
    "    mean_f = np.mean(f_df['BEVALUE'])\n",
    "    max_f = np.max(f_df['BEVALUE'])\n",
    "    med_f = np.median(f_df['BEVALUE'])\n",
    "    return {'mean_f': mean_f, 'max_f': max_f, 'med_f': med_f}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply to data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show all statistics to highlight classes and choose appropriate classification criterias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vehile 3\n",
      "{'mean_v': 36.843193566915566, 'med_v': 36.0, 'max_v': 227, 'max_trim_v': 91.0}\n",
      "{'mean_t': 1207.001399906673, 'max_t': 2328, 'quant_t': array([ 896., 1191., 1465., 1519., 1999.])}\n",
      "{'mean_f': 180.684451612903, 'max_f': 279.8, 'med_f': 187.85000000000002}\n",
      "Vehile 1\n",
      "{'mean_v': 56.243554189776646, 'med_v': 57.0, 'max_v': 129, 'max_trim_v': 119.0}\n",
      "{'mean_t': 2344.0295926301155, 'max_t': 4608, 'quant_t': array([1696., 2432., 3008., 3168., 4288.])}\n",
      "{'mean_f': 38.86536359814994, 'max_f': 60.0, 'med_f': 40.0}\n",
      "Vehile 5\n",
      "{'mean_v': 62.318233826237616, 'med_v': 65.0, 'max_v': 132, 'max_trim_v': 112.0}\n",
      "{'mean_t': 1910.7419759016018, 'max_t': 4857, 'quant_t': array([1522., 1977., 2401., 2486., 3063.])}\n",
      "{'mean_f': 40.34714247383985, 'max_f': 73.5, 'med_f': 41.1}\n",
      "Vehile 28\n",
      "{'mean_v': 57.01152110509744, 'med_v': 57.0, 'max_v': 122, 'max_trim_v': 108.0}\n",
      "{'mean_t': 2457.522518800099, 'max_t': 4672, 'quant_t': array([1984., 2560., 3072., 3168., 3872.])}\n",
      "{'mean_f': 16.823962580954827, 'max_f': 60.0, 'med_f': 0.0}\n",
      "Vehile 19\n",
      "{'mean_v': 3.70809346427362, 'med_v': 3.0, 'max_v': 57, 'max_trim_v': 11.0}\n",
      "{'mean_t': 1173.4152078774616, 'max_t': 1684, 'quant_t': array([ 914. , 1193.5, 1436. , 1462. , 1647. ])}\n",
      "{'mean_f': 29.95596925294238, 'max_f': 95.0, 'med_f': 26.2}\n"
     ]
    }
   ],
   "source": [
    "for i in ids:  # show all statistics for each vehicle\n",
    "    print(f'Vehile {i}')\n",
    "    print(velocity_data(i))\n",
    "    print(tachometer_data(i))\n",
    "    print(fuel_lvl_data(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a decision tree due to the statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify each vehicle 3 times as there are 3 types of classes:\n",
    "\n",
    "* Slow or fast\n",
    "* Cargo or 'passenger-oriented'\n",
    "* Loaded or commonly-used\n",
    "\n",
    "Loaded means vehicle is used with conditions above standart norms (revs count is too high)\n",
    "\n",
    "### To classify some statistics are used:\n",
    "\n",
    "* Maximum velocity (max_v)\n",
    "* Maximum trimmed velocity (calculate maximum from the subset, max_trim_v)\n",
    "* Maximum fuel level (max_f)\n",
    "* Mean fuel level (mean_f)\n",
    "* Revs 99 percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_vehicle(v_id, data_holder=raw_data_base):\n",
    "    # core classifying function -- decision tree used\n",
    "    velocity_dict = velocity_data(v_id, data_holder)  # calculate statistics\n",
    "    tachometer_dict = tachometer_data(v_id, data_holder)\n",
    "    fuel_dict = fuel_lvl_data(v_id, data_holder)\n",
    "    \n",
    "    categories = { 'slow': False, 'cargo': False, 'loaded': False }  # init categories dictionary\n",
    "    \n",
    "    # Classify\n",
    "    # Slow or fast\n",
    "    if velocity_dict['max_v'] < 80 and velocity_dict['max_trim_v'] < 50:\n",
    "        categories['slow'] = True\n",
    "        \n",
    "    # Cargo or not\n",
    "    if fuel_dict['max_f'] > 150 and fuel_dict['mean_f'] > 100:\n",
    "        categories['cargo'] = True\n",
    "        \n",
    "    # Normal or loaded\n",
    "    if tachometer_dict['quant_t'][-1] > 3900:\n",
    "        categories['loaded'] = True\n",
    "        \n",
    "    return categories\n",
    "\n",
    "def pretty_v_class(vehicle_name, ans_dict):\n",
    "    # Represent answer as a string\n",
    "    opposites_dict = { 'slow': 'fast', 'cargo': 'light weight', 'loaded': 'normal' }  # to convert False to string label\n",
    "    final_words = [x if ans_dict[x] else opposites_dict[x] for x in ans_dict]  # convert True-False answer flags to string labels\n",
    "    print('The vehicle {} is {}, {} and {}'.format(vehicle_name, final_words[0], final_words[1], final_words[2]))  # print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_all_vehicles():\n",
    "    # classify all and show summary\n",
    "    histograms = {  # histograms are used to show summary\n",
    "        'fast': 0,\n",
    "        'slow': 0,\n",
    "        'cargo': 0,\n",
    "        'light weight': 0,\n",
    "        'normal': 0,\n",
    "        'loaded': 0\n",
    "    }\n",
    "    \n",
    "    total = 0\n",
    "    opposites_dict = { 'slow': 'fast', 'cargo': 'light weight', 'loaded': 'normal' }\n",
    "    \n",
    "    for cur_id in ids:  # classify each vehicle\n",
    "        v_class = classify_vehicle(cur_id)\n",
    "        pretty_v_class(cur_id, v_class)\n",
    "        total += 1\n",
    "        for cur_class in v_class:  # aggregate histograms\n",
    "            if v_class[cur_class]:\n",
    "                histograms[cur_class] += 1\n",
    "            else:\n",
    "                histograms[opposites_dict[cur_class]] += 1\n",
    "    \n",
    "    print(\"\\nSummary\\n\")\n",
    "    for class_name in histograms:  # show summary results\n",
    "        print(f'{class_name}: {histograms[class_name]} ({histograms[class_name] / total * 100}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vehicle 3 is fast, cargo and normal\n",
      "The vehicle 1 is fast, light weight and loaded\n",
      "The vehicle 5 is fast, light weight and normal\n",
      "The vehicle 28 is fast, light weight and normal\n",
      "The vehicle 19 is slow, light weight and normal\n",
      "\n",
      "Summary\n",
      "\n",
      "fast: 4 (80.0%)\n",
      "slow: 1 (20.0%)\n",
      "cargo: 1 (20.0%)\n",
      "light weight: 4 (80.0%)\n",
      "normal: 4 (80.0%)\n",
      "loaded: 1 (20.0%)\n"
     ]
    }
   ],
   "source": [
    "classify_all_vehicles()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
