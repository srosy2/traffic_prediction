{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загружаем методы для поиска аномалий из anomalies.py, методы для слгаживания из smoothing.py, метода для оценки алгоритма из metrics.py, класс для препроцесса данных из  models.py и методы для доставания отрезков сливов и заправок drain_fuel.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import PreprocessModels\n",
    "from smoothing import exponential_smoothing, double_exponential_smoothing\n",
    "from anomalies import segments, detect_anomalies, upper_anomalies, lower_anomalies\n",
    "from metrics import segment_accuracy\n",
    "from drain_fuel import segments_drain_fuel, detect_segment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Методы для визуализации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "sns.set()\n",
    "from dateutil.parser import parse\n",
    "import numpy as np\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Методы для загрузки данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "from math import ceil, floor\n",
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Остальные методы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings                                  # `do not disturbe` mode\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np                               # vectors and matrices\n",
    "import pandas as pd                              # tables and data manipulations\n",
    "import matplotlib.pyplot as plt                  # plots\n",
    "import seaborn as sns                            # more plots\n",
    "\n",
    "from dateutil.relativedelta import relativedelta # working with dates with style\n",
    "from scipy.optimize import minimize              # for function minimization\n",
    "\n",
    "import statsmodels.formula.api as smf            # statistics and econometrics\n",
    "import statsmodels.tsa.api as smt\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as scs\n",
    "\n",
    "from itertools import product                    # some useful functions\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разные метрики для поиска аномалий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error, mean_squared_error, mean_squared_log_error\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"\"\n",
    "data_dir = os.path.join(root_path, \"unpacked\")\n",
    "\n",
    "data_files = os.listdir(data_dir)  # target files\n",
    "data_files = [x for x in data_files if x != 'readme.txt']  # remove readme\n",
    "\n",
    "\n",
    "def file_to_df(file):\n",
    "    \"\"\"Open file and create pandas data frame\"\"\"\n",
    "    full_path = os.path.join(data_dir, file)\n",
    "    return pd.read_csv(full_path, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get vehicle IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'28', '1', '3', '5', '19'}\n"
     ]
    }
   ],
   "source": [
    "regex_pattern = r\"vehicle(\\d*)\"  # ID is integer number comes right after vehicle word\n",
    "compiled_pattern = re.compile(regex_pattern)\n",
    "ids = compiled_pattern.findall(''.join(data_files))  # apply pattern to all file names\n",
    "ids = set(ids)  # get a set of unique numbers\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load info about a single vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file_id(v_id, key_lexem):\n",
    "    \"\"\"Key lexem determines file, for example, 'fuelLevel'\"\"\"\n",
    "    regex_pattern = re.compile(f\"(vehicle{v_id}_{key_lexem}\" + r\"_(\\w|\\d|_)*\\.csv)\")  # pattern to find appropriate name\n",
    "    pattern_match = regex_pattern.search('|'.join(data_files))  # search on a whole file set\n",
    "    needed_file = pattern_match.group(1)  # the file is found, now we can open it\n",
    "    return file_to_df(needed_file)\n",
    "    \n",
    "possible_lexems = ['fuelLevel', 'ingection', 'refueling2', 'speedAndHeight', 'tachometer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_files_id(v_id):\n",
    "    \"\"\"Generates a dictionary of all files describing a single vehicle\"\"\"\n",
    "    return {lex: open_file_id(v_id, lex) for lex in possible_lexems}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 Find refuelings with 5% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузга и препроцесс данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_base = {v_id: load_all_files_id(v_id) for v_id in ids} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_models = []\n",
    "for i in ids:\n",
    "    prep_models.append(PreprocessModels(raw_data_base[i]['fuelLevel'],raw_data_base[i]['ingection'],raw_data_base[i]['refueling2'],raw_data_base[i]['speedAndHeight'],raw_data_base[i]['tachometer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: x.preprocess_all_df(), prep_models))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Отрисовка всех машин"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotGraphics(axes, series, start_vec, end_vec, type_of_data, window=1):\n",
    " \n",
    "    drain, refueling = segments_drain_fuel(series, start_vec, end_vec, type_of_data, window)\n",
    "    \n",
    "    axes.add_trace(go.Scatter(\n",
    "        x=series.index,\n",
    "        y=series.BEVALUE,\n",
    "        mode='lines',\n",
    "        name='oil'\n",
    "    ))\n",
    "    \n",
    "    axes.add_trace(go.Scatter(\n",
    "        x=drain.index,\n",
    "        y=drain.BEVALUE,\n",
    "        mode='lines',\n",
    "        name='drain'\n",
    "    ))\n",
    "    \n",
    "    axes.add_trace(go.Scatter(\n",
    "        x=refueling.index,\n",
    "        y=refueling.BEVALUE,\n",
    "        mode='lines',\n",
    "        name='refueling'\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in prep_models:\n",
    "#     fig = go.Figure()\n",
    "#     plotGraphics(fig, i.df1, i.df3['STARTDATE'], i.df3['ENDDATE'], i.df3['bay/drain'])\n",
    "#     fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Идея заключается в нахождение верхних и нижних аномалий соединять их и считать их за заправки автомобиля"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Отрисовка граффиков с найдеными аномалиями и с окном = 2(Окно n- это сумма первого и n-1 элемента деленные на n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotMovingAverage(fig, series, check_series, window, plot_intervals=False, scale=1.96, plot_anomalies=False):\n",
    "\n",
    "    \"\"\"\n",
    "        series - dataframe with timeseries\n",
    "        window - rolling window size \n",
    "        plot_intervals - show confidence intervals\n",
    "        plot_anomalies - show anomalies \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    rolling_mean = series.rolling(window=window).mean().dropna()\n",
    "    \n",
    "    \n",
    "    if plot_intervals:\n",
    "        \n",
    "        upper_lower_bond, upper_upper_bond = segments(series,scale,window)\n",
    "        lower_lower_bond, lower_upper_bond = segments(series[::-1],scale,window)\n",
    "        \n",
    "        fig.add_trace(go.Scatter(x=upper_upper_bond.index, y=upper_upper_bond.BEVALUE, name='Upper Bond',mode='lines',\n",
    "                         line = dict(color='firebrick', width=1, dash='dot')))\n",
    "        fig.add_trace(go.Scatter(x=upper_lower_bond.index, y=upper_lower_bond.BEVALUE, name='Lower Bond',mode='lines',\n",
    "                         line = dict(color='firebrick', width=1, dash='dot')))\n",
    "        \n",
    "        if plot_anomalies:\n",
    "            \n",
    "            upper_anomalies = detect_anomalies(series, upper_lower_bond, upper_upper_bond, window)\n",
    "            lower_anomalies = detect_anomalies(series[::-1], lower_lower_bond, lower_upper_bond, window)\n",
    "\n",
    "            fig.add_trace(go.Scatter(x=upper_anomalies.index, y=upper_anomalies.BEVALUE,\n",
    "                    mode='markers', name='upper_markers', marker_size=10, marker_color='rgba(152, 0, 0, .8)'))\n",
    "            fig.add_trace(go.Scatter(x=lower_anomalies.index, y=lower_anomalies.BEVALUE,\n",
    "                    mode='markers', name='lower_markers', marker_size=10, marker_color='rgba(152, 0, 0, .8)'))\n",
    "    \n",
    "    \n",
    "    plotGraphics(fig, series[window:], check_series['STARTDATE'], check_series['ENDDATE'], check_series['bay/drain'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in prep_models:\n",
    "#     fig = go.Figure()\n",
    "#     plotMovingAverage(fig, i.df1, i.df3, 2,plot_intervals=True,plot_anomalies=True)\n",
    "#     fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Как видно, для каких-то графиков находит точки аномалии хорошо, а для каких-то нет, давайте дабавим сглаживания y^t=α⋅yt+(1−α)⋅y^t−1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotExponentialSmoothing(fig, series, df3, alpha, window=1, scale=1.96):\n",
    "    \"\"\"\n",
    "        Plots exponential smoothing with different alphas\n",
    "        \n",
    "        series - dataset with timestamps\n",
    "        alphas - list of floats, smoothing parameters\n",
    "        \n",
    "    \"\"\"\n",
    "    plotMovingAverage(fig, exponential_smoothing(series, alpha), df3, window,plot_intervals=True,plot_anomalies=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in prep_models:\n",
    "#     fig = go.Figure()\n",
    "#     plotExponentialSmoothing(fig, i.df1.BEVALUE, i.df3, alpha=0.8, window=3)\n",
    "#     fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## К сожаленнию, но у саммого обычного сглаживание есть минус в том, что все данные смещаются в сторону, следовательно надо как-то потом определять время, не понятно как\n",
    "## Давайте добавим возможность менять тренд графиков, чтобы аномалии можно было искать еще проще\n",
    "## ℓx=αyx+(1−α)(ℓx−1+bx−1)\n",
    "## bx=β(ℓx−ℓx−1)+(1−β)bx−1\n",
    "## y^x+1=ℓx+bx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotDoubleExponentialSmoothing(fig, series, df3, alpha, beta, window=1, scale=1.96):\n",
    "    \"\"\"\n",
    "        Plots double exponential smoothing with different alphas and betas\n",
    "        \n",
    "        series - dataset with timestamps\n",
    "        alphas - list of floats, smoothing parameters for level\n",
    "        betas - list of floats, smoothing parameters for trend\n",
    "    \"\"\"\n",
    "    plotMovingAverage(fig, double_exponential_smoothing(series, alpha, beta), df3, window, plot_intervals=True, plot_anomalies=True, scale=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in prep_models:\n",
    "#     fig = go.Figure()\n",
    "#     plotDoubleExponentialSmoothing(fig, i.df1.BEVALUE, i.df3, alpha=1, beta=0.3, window=2, scale=8)\n",
    "#     fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стало в некоторых местах получще"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Теперь можно заняться подборкой параметров и отрисовкой графиков, для понимания, что получилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotMovingAverageWithPredict(fig, series, df3, predict_series):\n",
    "    \n",
    "    plotGraphics(fig, series, df3['STARTDATE'], df3['ENDDATE'], df3['bay/drain'])\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=predict_series.index,\n",
    "        y=predict_series.BEVALUE,\n",
    "        mode='lines',\n",
    "        name='predict_fuel'\n",
    "    ))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9583333333333334\n",
      "0.41025641025641024\n",
      "0.6\n",
      "0.36363636363636365\n"
     ]
    }
   ],
   "source": [
    "for i in prep_models:\n",
    "    \n",
    "    upp = upper_anomalies(i.df1.BEVALUE, 1, 0,  2, 6)\n",
    "    low = lower_anomalies(i.df1.BEVALUE, 1, 0,  2, 6)\n",
    "    drain, refueling = segments_drain_fuel(i.df1, i.df3['STARTDATE'], i.df3['ENDDATE'], i.df3['bay/drain'])\n",
    "    try:\n",
    "        vec = detect_segment(low,upp,i.df1)\n",
    "        print(segment_accuracy(vec, refueling))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Давайте визуализируем, что получилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in prep_models:\n",
    "#     fig = go.Figure()\n",
    "#     upp = upper_anomalies(i.df1.BEVALUE, 1, 0,  2, 6)\n",
    "#     low = lower_anomalies(i.df1.BEVALUE, 1, 0,  2, 6)\n",
    "#     drain, refueling = segments_drain_fuel(i.df1, i.df3['STARTDATE'], i.df3['ENDDATE'], i.df3['bay/drain'])\n",
    "#     try:\n",
    "#         vec = detect_segment(low,upp,i.df1)\n",
    "#         fig = go.Figure()\n",
    "#         plotMovingAverageWithPredict(fig, i.df1, i.df3, vec)\n",
    "#         fig.show()\n",
    "#     except:\n",
    "#         pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Как видно, получилось, что давольно хорошо определяет, если поиграться с параметрами можно получить намного более хороший результат"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}